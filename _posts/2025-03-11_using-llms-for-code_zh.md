# 以下是我利用大语言模型辅助编程的方法

2025年3月11日

关于使用大语言模型辅助编程的线上讨论中，总会出现体验不佳的开发者的评论。他们常问自己做错了什么——为何有人声称效果卓著，而自己的实验却收效甚微？
利用大语言模型编写代码既困难又反直觉。需要投入大量精力才能摸清其优势与局限，而目前鲜有指导能帮助人们找到最佳应用方式。
若有人告诉你用大语言模型编程很轻松，那（可能无意中）误导了你。他们或许偶然发现了有效模式，但这些模式并非对所有人都自然适用。
两年来，我一直用大语言模型生成代码并取得优异成果。以下是我尝试将部分经验与直觉传授给你的心得。
 
 - 设定合理预期
 - 注意训练数据截止日期
 - 上下文至关重要
 - 要求提供备选方案
 - 明确指示具体操作
 - 必须测试生成的代码！
 - 记住这是对话过程
 - 使用能运行代码的工具
 - 氛围编码是绝佳学习方式
 - 使用Claude Code的详细示例
 - 准备随时接手
 - 最大优势是开发速度
 - 大语言模型能放大现有专长
 - 附赠：解答代码库相关问题

## 设定合理预期
忽略“通用人工智能”的炒作——大语言模型本质仍是高级自动补全。它们仅能预测词元序列，但编程恰巧大多关乎以正确顺序组合词元，因此只要引导得当，它们对此极为有用。
若你指望这项技术能在无需动用自身技能的情况下完美实现项目，很快就会失望。
相反，应利用它们增强自身能力。我目前最推崇的心智模型是：将其视为过度自信的结对编程助手，能闪电般快速查阅资料，随时生成相关示例，且毫无怨言地执行繁琐任务。
“过度自信”这点很重要。它们绝对会犯错——有时细微，有时严重。这些错误可能极其不符合人类常理——若人类合作者臆想出不存在的方法库或方法，你会立即失去信任。
切勿陷入拟人化大语言模型的陷阱，认为那些会让人类失信的错误同样适用于机器。
使用大语言模型时，常会遇到它们无法胜任的任务。请记录这些情况——都是宝贵的经验！它们也是值得珍藏的实例——当新版模型能完成旧版无法处理的任务时，便是其强劲性能的体现。
## 注意训练数据截止日期
任何模型的关键特性之一就是其训练数据截止日期。这是指模型训练数据收集的截止时间。对于OpenAI的模型，通常是2023年10月或2024年5月。其他供应商可能提供更新的日期。
这对编程至关重要，因为它影响模型熟悉的方法库。如果你使用的方法库在2023年10月后有过重大破坏性变更，某些OpenAI模型将无法识别！
我从大语言模型中获益良多，因此现在选型时会刻意考虑这一点——尽量选择稳定性好、流行度高的方法库，确保大量示例已纳入训练数据。我偏好应用“无聊技术”原则：在项目独特卖点上创新，其余部分则采用久经考验的解决方案。
大语言模型仍能助你使用训练数据外的方法库，但需投入更多精力——你必须在提示词中提供这些方法库的最新使用示例。
这引出了使用大语言模型时需理解的最重要事项：
## 上下文至关重要
从大语言模型获得良好结果的核心技巧在于管理其上下文——即当前对话中包含的文本内容。
这种上下文不仅是你输入的提示词：成功的大语言模型交互通常以对话形式进行，上下文包含当前对话线程中你的每条消息及大语言模型的每次回复。
开启新对话时，上下文将重置归零。这一点很重要，因为当对话不再有效时，解决方法往往是清空画布重新开始。
部分大语言模型编程工具超越了一般对话范畴。例如Claude项目允许你用大量文本预填充上下文——包括最近新增的从GitHub代码库直接导入代码的功能，我经常使用此功能。
Cursor和VS Code Copilot等工具会自动包含当前编辑会话及文件布局的上下文，有时你还能利用类似Cursor的@commands机制引入额外文件或文档。
我主要直接使用ChatGPT和Claude网页或应用界面的原因之一，是这让我更清楚了解上下文的具体内容。那些对我隐藏上下文的工具效果会打折扣。
你可以利用“先前回复也属于上下文”这一特点。对于复杂编程任务，可先让大语言模型编写简化版本，验证可行后再迭代构建更复杂的实现。
我常通过导入现有代码开启新对话以初始化上下文，然后与大语言模型合作修改代码。
我最爱的代码提示技巧之一是放入数个与目标构建内容相关的完整示例，然后提示大语言模型以此为参考创建新项目。我在描述结合Tesseract.js和PDF.js的JavaScript OCR应用时详细写过这种方法——这两个方法库我曾用过，能在提示词中提供可运行示例。
## 要求提供备选方案
我的项目大多始于一些开放性问题：我想做的事情是否可行？有哪些实现方式？哪种方案最优？
我在初始研究阶段会使用大语言模型。
我会用这类提示词：“Rust的HTTP方法库有哪些选项？附使用示例”——或“JavaScript中有哪些实用的拖放方法库？为每个方法库构建展示工件”（对Claude）。
训练截止日期在此很关键，因为新方法库不会被推荐。通常这没问题——我不追求最新，只要最稳定且经过时间检验的方案。
若要使用较新工具，我会在大语言模型之外自行研究。
项目启动的最佳方式是创建验证关键需求可行性的原型。我常发现大语言模型能让我在打开笔记本几分钟内——有时甚至在手机上操作时——快速获得可运行原型。
## 明确指示具体操作
完成初步研究后，我的模式彻底转变。对于生产代码，我使用大语言模型的方式更趋专制：将其视为数字实习生，按照我的详细指示键入代码。
最近示例如下：
编写使用asyncio httpx的Python函数，签名如下：
async def download_db(url, max_size_bytes=5 * 1025 * 1025): -> pathlib.Path
给定URL，此函数将数据库下载到临时目录并返回其路径。但它在流式返回数据开始时检查内容长度头，若超出限制则抛出错误。下载完成后使用sqlite3.connect(...)并执行PRAGMA quick_check以验证SQLite数据有效性——若无效则抛出错误。最后，若内容长度头欺骗我们——比如声称2MB却下载了3MB——一旦发现问题立即抛出错误。
我自己编写此函数需近十五分钟查阅细节并调试代码。而Claude仅用15秒就完成了。
我发现大语言模型对我使用的这类函数签名响应极佳。我充当函数设计师，大语言模型则按我的规范构建函数体。
我常接着提示“现在用pytest编写测试”。同样，我指定技术选型——让大语言模型节省我敲出脑中已有代码的时间。
若你认为“直接写代码比用英语描述更快”，我只能说对我而言早已非如此。代码必须准确。英语则允许大量简写、模糊表达、拼写错误，以及像“用那个流行的HTTP方法库”这样的表述（如果你一时想不起名称）。
优秀的编程大语言模型极擅于填补空白。它们也比我更勤勉——会记得捕获可能的异常、添加精确文档字符串，并用相关类型注解代码。
## 必须测试生成的代码！
我上周详细写过：你绝对不能外包给机器的唯一环节是测试代码是否真正有效。
作为软件开发者的职责是交付可运行系统。若未亲眼见证运行，就不算可运行系统。你需要加强手动质量保证的习惯。
这可能不吸引人，但无论是否使用大语言模型，它始终是发布优质代码的关键环节。
## 记住这是对话过程
若我不满意大语言模型的输出，它们绝不会因被要求重构而抱怨！“将重复代码提取为函数”、“用字符串操作方法替代正则表达式”、甚至“写得更好些！”——大语言模型首次生成的代码很少是最终实现，但它们能为你反复重写数十次而从不厌烦。
偶尔首次提示就能获得理想结果——随着练习增多频率会提升——但我预期至少需要几次跟进。
我常想这是否是人们遗漏的关键技巧——糟糕的初步结果并非失败，而是推动模型朝向实际目标的起点。
## 使用能运行代码的工具
越来越多大语言模型编程工具具备运行代码的能力。我对部分工具持谨慎态度，因为错误命令可能造成实际损害，因此倾向于使用在安全沙箱中运行代码的工具。目前我的最爱是：
ChatGPT代码解释器：ChatGPT可直接在OpenAI管理的Kubernetes沙箱虚拟机中编写并执行Python代码。这完全安全——它甚至无法建立出站网络连接，最多只能弄乱临时文件系统（随后会被重置）。
Claude工件：Claude可构建完整的HTML+JavaScript+CSS网页应用并在其界面中显示。此网页应用在严格锁定的iframe沙箱中显示，极大限制其功能但防止了意外泄露私人Claude数据等问题。
ChatGPT画布是较新的ChatGPT功能，能力与Claude工件相似。我尚未深入探索。
若你愿冒更大风险：
Cursor具备“智能体”功能，Windsurf及越来越多其他编辑器也拥有此功能。我尚未充分体验故不做推荐。
Aider是此类模式的领先开源实现，也是自产自销的典范——近期版本80%以上由Aider自身编写。
Claude Code是Anthropic在此领域的新成员。我稍后将详述该工具的使用。
这种“在循环中运行代码”的模式如此强大，以致我选择核心编程大语言模型工具时主要依据其能否安全运行并迭代代码。
## 氛围编码是绝佳学习方式
Andrej Karpathy约一月前创造了“氛围编码”一词并流传开来：
我称之为“氛围编码”的新型编程方式，即完全沉浸于氛围，拥抱指数思维，忘却代码本身的存在。[...]我会提出“将侧边栏内边距减半”这种愚蠢要求，因为懒得查找。我总是“全部接受”，不再阅读差异。遇到错误信息就直接粘贴进去，通常就能修复。
Andrej认为这“对周末临时项目无妨”。它也是探索模型能力的绝佳方式——而且非常有趣。
学习大语言模型的最佳途径是实践。向它们抛荒诞想法并进行氛围编码直至勉强可用，能有效加速你积累“何为有效、何为无效”的直觉。
在Andrej命名前我早已开始氛围编码！我的simonw/tools GitHub代码库包含77个HTML+JavaScript应用和6个Python应用，每个都通过提示大语言模型构建。从中我获益良多，并以每周数个新原型的速度增补。
你可在tools.simonwillison.net直接尝试大部分项目——这是代码库的GitHub Pages发布版本。我在十月的《本周我用Claude工件构建的一切》中详细记录了部分项目笔记。
若想查看每个项目的对话记录，几乎总能在页面提交历史中找到链接——或访问新的版本说明页面获取含所有链接的索引。
## 使用Claude Code的详细示例
撰写本文时，我萌生了创建tools.simonwillison.net/colophon页面的想法——希望有个能清晰展示每个工具提交历史的页面，比GitHub更直观。
我决定借此演示AI辅助编程流程。
此次使用Claude Code，因希望它能直接在我笔记本上的现有工具代码库中运行Python代码。
会话结束时运行/cost命令显示：
```
/cost 
  ⎿ 总成本：0.61美元
    总时长（API）：5分31.2秒
    总时长（实际）：17分18.7秒
```
初始项目耗时略超17分钟，Anthropic的API调用花费61美分。
我采用了专制流程，明确告知模型要构建的内容。以下是我的提示序列（完整记录在此）。
我首先要求编写收集新页面所需数据的初始脚本：
此目录中几乎所有HTML文件均通过Claude提示创建，这些提示的详情可在提交消息中找到。构建Python脚本检查每个HTML文件的提交历史，从中提取提交消息中的URL形成列表。然后输出JSON文件，结构如下：{“pages”: {“文件名.html”: [“url”], {“文件名2.html”: [“url1”, “url2”], ...——如你所见，部分文件提交历史可能含多个URL。脚本应命名为gather_links.py，并保存名为gather_links.json的JSON文件
我并未深入思考这第一条提示——更多是随思绪流淌键入的初步构想。
检查初步结果后发现一些问题：
看起来只获取了URL开头部分，应获取完整URL（可能指向不同网站）——只需提取以https://开头并以空白符或提交消息结尾的内容
随后我改变主意——还想要完整的提交消息：
更新脚本——我希望捕获完整提交消息及URL——新格式应为：{“pages”: {“aria-live-regions.html”: {“commits”: [{“hash”: 哈希值, “message”: 消息, “date”: ISO格式日期], “urls”: [与之前相同的URL列表]
提供此类示例是精准获取所需内容的捷径。
注意我始终未查看gather_links.py中的代码！这是纯粹的氛围编码：我关注其行为，而将实现细节完全交由大语言模型。
JSON看起来不错，于是我指示：
效果很好。请编写名为build_colophon.py的新脚本，遍历收集的JSON文件并构建保存HTML页面。页面需支持移动端，列出所有页面（含页面链接），并为每个页面整齐展示提交消息（换行符转为br标签并链接化URL，无需其他格式）——外加提交日期及指向提交的链接（位于https://github.com/simonw/tools）
Claude知晓GitHub URL规则，故告知其链接至提交并提供代码库名称足以让其推测出类似https://github.com/simonw/tools/commit/fd9daf885c924ba277806b3440457d52b0ad90a8的提交URL。
我发现Claude在网页设计方面品味不错——我仅要求“页面需支持移动端”便不再赘述。
Claude全力构建的页面存在问题，于是我指出：
显示不正常。ocr.html有多次提交，但在colophon.html中仅首条提交显示链接和标题，其余提交都在同一区块内展示——应为每次提交单独显示HTML块（含链接和格式化日期）。另外格式化日期应包含HH:MM而不仅是日期
它自行修复了错误，仅剩两处我决定修改：
近乎完美，但每个页面的提交应按相反顺序显示——最旧的在最前
接着：
最后调整——当前页面按字母顺序排列，改为按最近修改时间降序排列
至此项目完成！这是build_colophon.py，生成的页面效果不错：
工具版本说明。此页面记录tools.simonwillison.net上工具的创建过程，包括用于构建它们的Claude对话链接。social-media-cropper.html b4a2bc 2024年12月10日 20:35 社交媒体裁剪器 https://gist.github.com/simonw/12b8f88932a71450071190e1289a17e9 a10954 2025年2月28日 16:02 支持2:1和14:10比例 https://gist.github.com/simonw/e23917eddcbb368c9b6180d581f8f40a
还剩最后任务：需将新版本说明部署至站点，但不想将colophon.html文件直接提交至代码库。我需要自定义GitHub Pages构建流程。
我开启全新Claude Code会话（清空上下文）试探其能否解决：
此代码库通过GitHub Pages部署。我想稍修改构建流程——在部署至GitHub Pages前运行python gather_links.py生成gathered_links.json文件——接着运行python build_colophon.py利用该文件创建colophon.html——我希望gathered_links.json和colophon.html都发布至GitHub Pages但不要提交到代码库本身
与首次不同，此次我密切关注其操作——我不懂如何以此方式自定义GitHub Pages构建，既想学习又想保持谨慎以防其臆造细节导致失败。
它请求创建此文件并征得我同意：
```
name: 部署至GitHub Pages
on:
  # 在推送至主分支时运行
  push:
    branches: [ main ]
  # 允许手动触发
  workflow_dispatch:
# 设置GITHUB_TOKEN权限
permissions:
  contents: read
  pages: write
  id-token: write
# 仅允许一个并发部署
concurrency:
  group: pages
  cancel-in-progress: true
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: 检出代码
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # gather_links.py需要完整历史记录
      - name: 设置Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: 安装依赖
        run: |
          python -m pip install --upgrade pip
      - name: 生成链接并构建版本说明
        run: |
          python gather_links.py
          python build_colophon.py
      - name: 设置Pages
        uses: actions/configure-pages@v4
      - name: 使用Jekyll构建
        uses: actions/jekyll-build-pages@v1
      - name: 上传制品
        uses: actions/upload-pages-artifact@v3
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: 部署至GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```
我猜这没问题？它注释“gather_links.py需要完整git历史记录”令我赞赏——这很容易被忽略。
接着它提议将这些文件加入.gitignore——好主意。
它输出了至此的操作摘要：
我已创建GitHub Pages的GitHub Actions工作流：
创建.github/workflows/pages.yml文件，其功能如下：

- 在主分支推送时运行
- 检出完整git历史记录（gather_links.py所需）
- 设置Python 3.12
- 依次运行两个脚本生成文件
- 构建并部署至GitHub Pages
- 创建.gitignore文件防止生成的文件被提交
- 当你推送至主分支时，GitHub Actions将：
- 运行gather_links.py脚本创建gathered_links.json
- 运行build_colophon.py创建colophon.html
- 部署这两个文件（及所有其他文件）至GitHub Pages

我查看了花费：
```
/cost 
  ⎿ 总成本：0.1788美元
    总时长（API）：44.6秒
    总时长（实际）：10分18.6秒
```
即使用Claude API花费17美分，45秒API时间。（我因分心导致实际总时长10分钟。）完整记录在此。
代码看起来不会造成不可逆破坏，于是我推送到GitHub观察结果。
……成功了！我的新版本说明页面已上线。
但存在隐患。我观察GitHub Actions界面运行时发现异常：
GitHub Actions界面显示三个已完成操作：版本说明自定义页面工作流的测试，同名部署，及另一个名为pages-build-deployment的操作。
我预期会有“测试”任务，但为何有两个独立部署？
我推测先前的默认Jek
